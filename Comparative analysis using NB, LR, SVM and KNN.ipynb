{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from textblob import Word\n",
    "\n",
    "import snowballstemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Documents\\project\\csv\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\ACER\\Documents\\project\\csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv(\"clean_tweetstextblobbinary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1499\n",
       "negative     616\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = my_df[['Content', 'Sentiment']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['Sentiment']).count().plot(kind='bar', figsize=(8, 6), rot=0, legend=False, title='Number of tweets by class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "cleaned_tweets = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # filerting out all the stopwords \n",
    "    words_without_stopwords = [word for word in row.Content.split() if not word in stopwords_set]\n",
    "    \n",
    "    # finally creating tweets list of tuples containing stopwords(list) and sentimentType \n",
    "    cleaned_tweets.append(' '.join(words_without_stopwords))\n",
    "\n",
    "df['Content'] = cleaned_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# Tokenization\n",
    "tokenized_tweet = df['Content'].apply(lambda x: x.split())\n",
    "# Finding Lemma for each word\n",
    "word_lemmatizer = WordNetLemmatizer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [word_lemmatizer.lemmatize(i) for i in x])\n",
    "#joining words into sentences (from where they came from)\n",
    "for i, tokens in enumerate(tokenized_tweet):\n",
    "    tokenized_tweet[i] = ' '.join(tokens)\n",
    "\n",
    "df['Content'] = tokenized_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# BOW features\n",
    "bow_word_vectorizer = CountVectorizer(max_df=1.0, min_df=1, stop_words='english')\n",
    "# bag-of-words feature matrix\n",
    "bow_word_feature = bow_word_vectorizer.fit_transform(df['Content'])\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf_word_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, stop_words='english')\n",
    "# TF-IDF feature matrix\n",
    "tfidf_word_feature = tfidf_word_vectorizer.fit_transform(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "#Train, test splitting\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df['Content'].values, df['target'].values, test_size=0.20, random_state=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_model(X_train, X_test, y_train, y_test):\n",
    "    naive_classifier = BernoulliNB()\n",
    "    naive_classifier.fit(X_train.toarray(), y_train)\n",
    "\n",
    "    # predictions over test set\n",
    "    predictions = naive_classifier.predict(X_test.toarray())\n",
    "    \n",
    "    # calculating f1 score\n",
    "    print(f'F1 Score - {f1_score(y_test, predictions)}')\n",
    "    print(f'Accuracy score- {metrics.accuracy_score(y_test, predictions)}')\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(f'confusion_matrix-{confusion_matrix(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - 0.8404802744425386\n",
      "Accuracy score- 0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19       197\n",
      "           1       0.74      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.70      0.54      0.52       698\n",
      "weighted avg       0.72      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 22 175]\n",
      " [ 11 490]]\n",
      "Wall time: 8.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "naive_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - 0.8404802744425386\n",
      "Accuracy score- 0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19       197\n",
      "           1       0.74      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.70      0.54      0.52       698\n",
      "weighted avg       0.72      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 22 175]\n",
      " [ 11 490]]\n",
      "Wall time: 799 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "naive_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logicistregression(X_train, X_test, y_train, y_test):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train.toarray(), y_train)\n",
    "\n",
    "    # predictions over test set\n",
    "    predictions = lr.predict(X_test.toarray())\n",
    "    \n",
    "    # calculating f1 score\n",
    "    print(f'F1 Score - {f1_score(y_test, predictions)}')\n",
    "    print(f'Accuracy score- {metrics.accuracy_score(y_test, predictions)}')\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(f'confusion_matrix-{confusion_matrix(y_test,predictions)}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - 0.8537477148080438\n",
      "Accuracy score- 0.7707736389684814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.36      0.47       197\n",
      "           1       0.79      0.93      0.85       501\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       698\n",
      "   macro avg       0.73      0.65      0.66       698\n",
      "weighted avg       0.76      0.77      0.75       698\n",
      "\n",
      "confusion_matrix-[[ 71 126]\n",
      " [ 34 467]]\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "logicistregression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - 0.8412162162162162\n",
      "Accuracy score- 0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.06      0.11       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.76      0.53      0.48       698\n",
      "weighted avg       0.75      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 12 185]\n",
      " [  3 498]]\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "logicistregression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supportvector(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf = OneVsRestClassifier(svm.SVC(gamma=0.01, C=100., probability=True, class_weight='balanced', kernel='rbf'))\n",
    "    clf.fit(X_train.toarray(), y_train)\n",
    "\n",
    "    # predictions over test set\n",
    "    \n",
    "    predictions = clf.predict(X_test.toarray())\n",
    "    \n",
    "    # calculating f1 score\n",
    "    print(f'F1 Score - {f1_score(y_test, predictions)}')\n",
    "    print(f'Accuracy score- {metrics.accuracy_score(y_test, predictions)}')\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(f'confusion_matrix-{confusion_matrix(y_test,predictions)}')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - 0.8388941849380361\n",
      "Accuracy score- 0.7578796561604585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.45      0.51       197\n",
      "           1       0.80      0.88      0.84       501\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       698\n",
      "   macro avg       0.70      0.67      0.68       698\n",
      "weighted avg       0.74      0.76      0.75       698\n",
      "\n",
      "confusion_matrix-[[ 89 108]\n",
      " [ 61 440]]\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "supportvector(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score - 0.842911877394636\n",
      "Accuracy score- 0.7650429799426934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.48      0.53       197\n",
      "           1       0.81      0.88      0.84       501\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       698\n",
      "   macro avg       0.71      0.68      0.69       698\n",
      "weighted avg       0.75      0.77      0.76       698\n",
      "\n",
      "confusion_matrix-[[ 94 103]\n",
      " [ 61 440]]\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "supportvector(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KNN\n",
    "#import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneigbors(X_train, X_test, y_train, y_test):\n",
    "    #trying to determine the best knearest neighbor\n",
    "    for i in range(1,51):\n",
    "        knn=KNeighborsClassifier(n_neighbors = i)\n",
    "        knnModel = knn.fit(X_train.toarray(),y_train)\n",
    "        knnPredict =knnModel.predict(X_test.toarray())\n",
    "        w = f1_score(y_test, knnPredict)\n",
    "        x = metrics.accuracy_score(y_test, knnPredict)\n",
    "        b = classification_report(y_test, knnPredict)\n",
    "        print (i)\n",
    "        print (w)\n",
    "        print(x) \n",
    "        print (b)\n",
    "        print(f'confusion_matrix-{confusion_matrix(y_test,knnPredict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8403361344537815\n",
      "0.7277936962750716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.04      0.08       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.81      0.52      0.46       698\n",
      "weighted avg       0.77      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[  8 189]\n",
      " [  1 500]]\n",
      "2\n",
      "0.7822736030828517\n",
      "0.6762177650429799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.34      0.37       197\n",
      "           1       0.76      0.81      0.78       501\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       698\n",
      "   macro avg       0.58      0.57      0.58       698\n",
      "weighted avg       0.66      0.68      0.67       698\n",
      "\n",
      "confusion_matrix-[[ 66 131]\n",
      " [ 95 406]]\n",
      "3\n",
      "0.8256721595836948\n",
      "0.7120343839541547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.11      0.17       197\n",
      "           1       0.73      0.95      0.83       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.59      0.53      0.50       698\n",
      "weighted avg       0.65      0.71      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 21 176]\n",
      " [ 25 476]]\n",
      "4\n",
      "0.8133704735376045\n",
      "0.7120343839541547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.30      0.37       197\n",
      "           1       0.76      0.87      0.81       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.62      0.59      0.59       698\n",
      "weighted avg       0.68      0.71      0.69       698\n",
      "\n",
      "confusion_matrix-[[ 59 138]\n",
      " [ 63 438]]\n",
      "5\n",
      "0.8320278503046127\n",
      "0.7234957020057307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.14      0.22       197\n",
      "           1       0.74      0.95      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.64      0.55      0.53       698\n",
      "weighted avg       0.68      0.72      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 27 170]\n",
      " [ 23 478]]\n",
      "6\n",
      "0.8155515370705244\n",
      "0.7077363896848138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.22      0.30       197\n",
      "           1       0.75      0.90      0.82       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.60      0.56      0.56       698\n",
      "weighted avg       0.67      0.71      0.67       698\n",
      "\n",
      "confusion_matrix-[[ 43 154]\n",
      " [ 50 451]]\n",
      "7\n",
      "0.8254799301919721\n",
      "0.7134670487106017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.13      0.20       197\n",
      "           1       0.73      0.94      0.83       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.60      0.54      0.51       698\n",
      "weighted avg       0.66      0.71      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 25 172]\n",
      " [ 28 473]]\n",
      "8\n",
      "0.8200537153088631\n",
      "0.7120343839541547\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.20      0.28       197\n",
      "           1       0.74      0.91      0.82       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.61      0.56      0.55       698\n",
      "weighted avg       0.67      0.71      0.67       698\n",
      "\n",
      "confusion_matrix-[[ 39 158]\n",
      " [ 43 458]]\n",
      "9\n",
      "0.8343451864700782\n",
      "0.7263610315186246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.13      0.21       197\n",
      "           1       0.74      0.96      0.83       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.65      0.55      0.52       698\n",
      "weighted avg       0.69      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 26 171]\n",
      " [ 20 481]]\n",
      "10\n",
      "0.8284444444444444\n",
      "0.7234957020057307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29       197\n",
      "           1       0.75      0.93      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.64      0.56      0.56       698\n",
      "weighted avg       0.68      0.72      0.68       698\n",
      "\n",
      "confusion_matrix-[[ 39 158]\n",
      " [ 35 466]]\n",
      "11\n",
      "0.8366464995678479\n",
      "0.7292263610315186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.13      0.21       197\n",
      "           1       0.74      0.97      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.67      0.55      0.52       698\n",
      "weighted avg       0.70      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 25 172]\n",
      " [ 17 484]]\n",
      "12\n",
      "0.8345070422535212\n",
      "0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.18      0.28       197\n",
      "           1       0.75      0.95      0.83       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.66      0.56      0.56       698\n",
      "weighted avg       0.70      0.73      0.68       698\n",
      "\n",
      "confusion_matrix-[[ 36 161]\n",
      " [ 27 474]]\n",
      "13\n",
      "0.8362068965517242\n",
      "0.7277936962750716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.12      0.19       197\n",
      "           1       0.74      0.97      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.66      0.54      0.52       698\n",
      "weighted avg       0.69      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 23 174]\n",
      " [ 16 485]]\n",
      "14\n",
      "0.8363954505686788\n",
      "0.7320916905444126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.17      0.26       197\n",
      "           1       0.74      0.95      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.67      0.56      0.55       698\n",
      "weighted avg       0.70      0.73      0.67       698\n",
      "\n",
      "confusion_matrix-[[ 33 164]\n",
      " [ 23 478]]\n",
      "15\n",
      "0.8399311531841652\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.12      0.21       197\n",
      "           1       0.74      0.97      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.69      0.55      0.52       698\n",
      "weighted avg       0.71      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 24 173]\n",
      " [ 13 488]]\n",
      "16\n",
      "0.8408304498269896\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.14      0.23       197\n",
      "           1       0.74      0.97      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.70      0.56      0.54       698\n",
      "weighted avg       0.72      0.74      0.67       698\n",
      "\n",
      "confusion_matrix-[[ 28 169]\n",
      " [ 15 486]]\n",
      "17\n",
      "0.8419243986254294\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.12      0.21       197\n",
      "           1       0.74      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.71      0.55      0.52       698\n",
      "weighted avg       0.72      0.74      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 24 173]\n",
      " [ 11 490]]\n",
      "18\n",
      "0.8413793103448275\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.13      0.22       197\n",
      "           1       0.74      0.97      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.70      0.55      0.53       698\n",
      "weighted avg       0.72      0.74      0.67       698\n",
      "\n",
      "confusion_matrix-[[ 26 171]\n",
      " [ 13 488]]\n",
      "19\n",
      "0.8421955403087479\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.12      0.20       197\n",
      "           1       0.74      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.72      0.55      0.52       698\n",
      "weighted avg       0.73      0.74      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 23 174]\n",
      " [ 10 491]]\n",
      "20\n",
      "0.8393782383419688\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.13      0.22       197\n",
      "           1       0.74      0.97      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.69      0.55      0.53       698\n",
      "weighted avg       0.71      0.73      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 26 171]\n",
      " [ 15 486]]\n",
      "21\n",
      "0.8398637137989778\n",
      "0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.09      0.15       197\n",
      "           1       0.73      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.71      0.54      0.50       698\n",
      "weighted avg       0.72      0.73      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 17 180]\n",
      " [  8 493]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "0.8349016253207869\n",
      "0.7234957020057307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.09      0.15       197\n",
      "           1       0.73      0.97      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.65      0.53      0.49       698\n",
      "weighted avg       0.68      0.72      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 17 180]\n",
      " [ 13 488]]\n",
      "23\n",
      "0.8381601362862011\n",
      "0.7277936962750716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.08      0.14       197\n",
      "           1       0.73      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.69      0.53      0.49       698\n",
      "weighted avg       0.71      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 16 181]\n",
      " [  9 492]]\n",
      "24\n",
      "0.8349016253207869\n",
      "0.7234957020057307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.09      0.15       197\n",
      "           1       0.73      0.97      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.65      0.53      0.49       698\n",
      "weighted avg       0.68      0.72      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 17 180]\n",
      " [ 13 488]]\n",
      "25\n",
      "0.8394222599830076\n",
      "0.7292263610315186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.08      0.14       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.71      0.53      0.49       698\n",
      "weighted avg       0.72      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 15 182]\n",
      " [  7 494]]\n",
      "26\n",
      "0.841296928327645\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.10      0.17       197\n",
      "           1       0.73      0.98      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.72      0.54      0.51       698\n",
      "weighted avg       0.73      0.73      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 19 178]\n",
      " [  8 493]]\n",
      "27\n",
      "0.8411214953271029\n",
      "0.7320916905444126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.08      0.15       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.73      0.53      0.49       698\n",
      "weighted avg       0.73      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 16 181]\n",
      " [  6 495]]\n",
      "28\n",
      "0.8418367346938775\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.09      0.15       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.74      0.54      0.50       698\n",
      "weighted avg       0.73      0.73      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 17 180]\n",
      " [  6 495]]\n",
      "29\n",
      "0.8430873621713315\n",
      "0.7349570200573066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.08      0.15       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.77      0.54      0.50       698\n",
      "weighted avg       0.75      0.73      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 16 181]\n",
      " [  4 497]]\n",
      "30\n",
      "0.8428207306711979\n",
      "0.7349570200573066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.09      0.16       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.75      0.54      0.50       698\n",
      "weighted avg       0.74      0.73      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 17 180]\n",
      " [  5 496]]\n",
      "31\n",
      "0.8443316412859561\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.08      0.14       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.81      0.54      0.49       698\n",
      "weighted avg       0.77      0.74      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 15 182]\n",
      " [  2 499]]\n",
      "32\n",
      "0.8457627118644069\n",
      "0.7392550143266475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.09      0.16       197\n",
      "           1       0.73      1.00      0.85       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.81      0.54      0.50       698\n",
      "weighted avg       0.78      0.74      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 17 180]\n",
      " [  2 499]]\n",
      "33\n",
      "0.8429054054054053\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.07      0.12       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.80      0.53      0.48       698\n",
      "weighted avg       0.77      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 13 184]\n",
      " [  2 499]]\n",
      "34\n",
      "0.8443316412859561\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.08      0.14       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.81      0.54      0.49       698\n",
      "weighted avg       0.77      0.74      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 15 182]\n",
      " [  2 499]]\n",
      "35\n",
      "0.8407750631844987\n",
      "0.7292263610315186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.05      0.10       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.78      0.52      0.47       698\n",
      "weighted avg       0.76      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 10 187]\n",
      " [  2 499]]\n",
      "36\n",
      "0.8443316412859561\n",
      "0.7363896848137536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.08      0.14       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       698\n",
      "   macro avg       0.81      0.54      0.49       698\n",
      "weighted avg       0.77      0.74      0.65       698\n",
      "\n",
      "confusion_matrix-[[ 15 182]\n",
      " [  2 499]]\n",
      "37\n",
      "0.8429054054054053\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.07      0.12       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.80      0.53      0.48       698\n",
      "weighted avg       0.77      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 13 184]\n",
      " [  2 499]]\n",
      "38\n",
      "0.8426395939086294\n",
      "0.7335243553008596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.07      0.13       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.78      0.53      0.49       698\n",
      "weighted avg       0.76      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 14 183]\n",
      " [  3 498]]\n",
      "39\n",
      "0.8436179205409974\n",
      "0.7349570200573066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.07      0.13       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.80      0.53      0.49       698\n",
      "weighted avg       0.77      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 14 183]\n",
      " [  2 499]]\n",
      "40\n",
      "0.8433530906011855\n",
      "0.7349570200573066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.08      0.14       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.78      0.54      0.49       698\n",
      "weighted avg       0.76      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 15 182]\n",
      " [  3 498]]\n",
      "41\n",
      "0.8414839797639123\n",
      "0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.06      0.10       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.79      0.53      0.47       698\n",
      "weighted avg       0.76      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 11 186]\n",
      " [  2 499]]\n",
      "42\n",
      "0.841927303465765\n",
      "0.7320916905444126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.07      0.12       197\n",
      "           1       0.73      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.77      0.53      0.48       698\n",
      "weighted avg       0.75      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 13 184]\n",
      " [  3 498]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "0.8414839797639123\n",
      "0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.06      0.10       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.79      0.53      0.47       698\n",
      "weighted avg       0.76      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 11 186]\n",
      " [  2 499]]\n",
      "44\n",
      "0.8421940928270042\n",
      "0.7320916905444126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.06      0.11       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.79      0.53      0.48       698\n",
      "weighted avg       0.77      0.73      0.64       698\n",
      "\n",
      "confusion_matrix-[[ 12 185]\n",
      " [  2 499]]\n",
      "45\n",
      "0.8414839797639123\n",
      "0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.06      0.10       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.79      0.53      0.47       698\n",
      "weighted avg       0.76      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 11 186]\n",
      " [  2 499]]\n",
      "46\n",
      "0.8414839797639123\n",
      "0.7306590257879656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.06      0.10       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.79      0.53      0.47       698\n",
      "weighted avg       0.76      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 11 186]\n",
      " [  2 499]]\n",
      "47\n",
      "0.8400673400673402\n",
      "0.7277936962750716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.05      0.09       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.77      0.52      0.46       698\n",
      "weighted avg       0.75      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[  9 188]\n",
      " [  2 499]]\n",
      "48\n",
      "0.8407750631844987\n",
      "0.7292263610315186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.05      0.10       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.78      0.52      0.47       698\n",
      "weighted avg       0.76      0.73      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 10 187]\n",
      " [  2 499]]\n",
      "49\n",
      "0.8393608074011774\n",
      "0.7263610315186246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.04      0.08       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.76      0.52      0.46       698\n",
      "weighted avg       0.75      0.73      0.62       698\n",
      "\n",
      "confusion_matrix-[[  8 189]\n",
      " [  2 499]]\n",
      "50\n",
      "0.8393608074011774\n",
      "0.7263610315186246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.04      0.08       197\n",
      "           1       0.73      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       698\n",
      "   macro avg       0.76      0.52      0.46       698\n",
      "weighted avg       0.75      0.73      0.62       698\n",
      "\n",
      "confusion_matrix-[[  8 189]\n",
      " [  2 499]]\n",
      "Wall time: 19min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "kneigbors(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8299912816041848\n",
      "0.7206303724928367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.14      0.22       197\n",
      "           1       0.74      0.95      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.63      0.54      0.52       698\n",
      "weighted avg       0.68      0.72      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 27 170]\n",
      " [ 25 476]]\n",
      "2\n",
      "0.8111510791366906\n",
      "0.6991404011461319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.19      0.26       197\n",
      "           1       0.74      0.90      0.81       501\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       698\n",
      "   macro avg       0.58      0.54      0.54       698\n",
      "weighted avg       0.65      0.70      0.66       698\n",
      "\n",
      "confusion_matrix-[[ 37 160]\n",
      " [ 50 451]]\n",
      "3\n",
      "0.8307952622673437\n",
      "0.7134670487106017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.04      0.07       197\n",
      "           1       0.72      0.98      0.83       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.57      0.51      0.45       698\n",
      "weighted avg       0.63      0.71      0.61       698\n",
      "\n",
      "confusion_matrix-[[  7 190]\n",
      " [ 10 491]]\n",
      "4\n",
      "0.8310580204778157\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.07      0.12       197\n",
      "           1       0.73      0.97      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.60      0.52      0.47       698\n",
      "weighted avg       0.66      0.72      0.63       698\n",
      "\n",
      "confusion_matrix-[[ 13 184]\n",
      " [ 14 487]]\n",
      "5\n",
      "0.8336134453781513\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.02      0.04       197\n",
      "           1       0.72      0.99      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.58      0.51      0.44       698\n",
      "weighted avg       0.64      0.72      0.61       698\n",
      "\n",
      "confusion_matrix-[[  4 193]\n",
      " [  5 496]]\n",
      "6\n",
      "0.8350168350168351\n",
      "0.7191977077363897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.03      0.06       197\n",
      "           1       0.72      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.63      0.51      0.45       698\n",
      "weighted avg       0.67      0.72      0.62       698\n",
      "\n",
      "confusion_matrix-[[  6 191]\n",
      " [  5 496]]\n",
      "7\n",
      "0.8348700754400671\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03       197\n",
      "           1       0.72      0.99      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.61      0.50      0.43       698\n",
      "weighted avg       0.66      0.72      0.61       698\n",
      "\n",
      "confusion_matrix-[[  3 194]\n",
      " [  3 498]]\n",
      "8\n",
      "0.8355704697986577\n",
      "0.7191977077363897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.02      0.04       197\n",
      "           1       0.72      0.99      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.65      0.51      0.44       698\n",
      "weighted avg       0.68      0.72      0.61       698\n",
      "\n",
      "confusion_matrix-[[  4 193]\n",
      " [  3 498]]\n",
      "9\n",
      "0.8348700754400671\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.02      0.03       197\n",
      "           1       0.72      0.99      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.61      0.50      0.43       698\n",
      "weighted avg       0.66      0.72      0.61       698\n",
      "\n",
      "confusion_matrix-[[  3 194]\n",
      " [  3 498]]\n",
      "10\n",
      "0.8338926174496643\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.02      0.03       197\n",
      "           1       0.72      0.99      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.57      0.50      0.43       698\n",
      "weighted avg       0.64      0.72      0.61       698\n",
      "\n",
      "confusion_matrix-[[  3 194]\n",
      " [  4 497]]\n",
      "11\n",
      "0.8354218880534671\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.01       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.61      0.50      0.42       698\n",
      "weighted avg       0.66      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  1 196]\n",
      " [  1 500]]\n",
      "12\n",
      "0.8361204013377925\n",
      "0.7191977077363897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.01      0.02       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.69      0.50      0.43       698\n",
      "weighted avg       0.70      0.72      0.61       698\n",
      "\n",
      "confusion_matrix-[[  2 195]\n",
      " [  1 500]]\n",
      "13\n",
      "0.83375104427736\n",
      "0.7148997134670487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.71      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  2 499]]\n",
      "14\n",
      "0.83375104427736\n",
      "0.7148997134670487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.71      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  2 499]]\n",
      "15\n",
      "0.8347245409015025\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  1 500]]\n",
      "16\n",
      "0.83375104427736\n",
      "0.7148997134670487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.71      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  2 499]]\n",
      "17\n",
      "0.8347245409015025\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  1 500]]\n",
      "18\n",
      "0.8347245409015025\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  1 500]]\n",
      "19\n",
      "0.8347245409015025\n",
      "0.7163323782234957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.83       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.51      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  1 500]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n",
      "29\n",
      "0.835696413678065\n",
      "0.7177650429799427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       197\n",
      "           1       0.72      1.00      0.84       501\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       698\n",
      "   macro avg       0.36      0.50      0.42       698\n",
      "weighted avg       0.52      0.72      0.60       698\n",
      "\n",
      "confusion_matrix-[[  0 197]\n",
      " [  0 501]]\n",
      "Wall time: 11min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_word_feature, df['target'], test_size=0.33, random_state=150)\n",
    "kneigbors(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_coefs(vocab, coefs, n):\n",
    "    coef_df = pd.DataFrame({'vocab': vocab, 'coef':coefs.reshape(-1)})\n",
    "    return coef_df.sort_values('coef', ascending=False).reset_index(drop=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tokens_coefs(df, ax, label):\n",
    "    df.sort_values('coef').plot.barh(legend=False, ax=ax)\n",
    "    ax.set_yticklabels(df['vocab'].values.tolist()[::-1])\n",
    "    ax.set_title(label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('xtick', labelsize=14)\n",
    "plt.rc('ytick', labelsize=14)\n",
    "sns.set_style(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
